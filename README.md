# Comparison of CNN and Transformer Models for Optical Filter Classification

## Overview
Automatic classification of optical filters from spectral measurements is important for optical system design and characterization. This project compares Convolutional Neural Networks (CNNs) and Transformer-based models for classifying optical filters using one-dimensional absorption spectra. A synthetic dataset of four filter types—long-pass, short-pass, band-pass, and neutral-density—was generated over the wavelength range 400–800 nm. Both models were trained under identical conditions and evaluated using metrics such as classification accuracy, confusion matrices, and training behavior analysis. Results show that CNNs achieve slightly higher final accuracy, while Transformers converge faster and capture global spectral dependencies, highlighting a trade-off between local feature extraction and global representation.


## Objective
This project aims to implement and compare deep learning models for optical filter classification using spectral data. Specifically, it seeks to:

1. Implement CNN and Transformer models for classifying optical filters.
2. Compare their performance and robustness under identical experimental conditions.
3. Assess the suitability of attention mechanisms for medium-sized spectral datasets.


## Project Structure 
The project directory is organized as follows:
```
optical_spectra_project/
│
├── data/
│   ├── dataset/                  # Raw generated spectra
│   │   └── synthetic_spectra_dataset.npz
│   ├── preview/
│   │   └── spectra_preview.txt
│   ├── processed/            # Normalized and split data
│   │   └── spectra_preprocessed.npz
│   └── metadata/
│       ├── class_mapping.json
│       └── dataset_description.txt
├── models/           
│   ├── baseline_cnn_best.pth
│   ├── transformer_best.pth│
│   └── logs/
│       ├── cnn_training_history.npz
│       └── transformer_training_history.npz
├── output/
├── src/
│   ├── generate_spectra.py   # Synthetic dataset generation
│   ├── preprocess.py         # Normalization & splits
│   ├── model.py              # Model definitions
│   ├── test_evaluation.py          
│   ├── train_CNN.py          
│   ├── train_transformer.py          
│   ├── visualize.py   
│   └── utils/
│       ├── metrics.py
│       └── plots.py 
├── Optical Spectra Project Preprint.pdf
├── requirements.txt
└── README.md
```

## Setup Instructions
Follow these steps to run the project:
1. **Download the project:**
    Clone the repository or unzip the project folder. The preprocessed dataset is included in the `data/preprocessed\` directory.

2. **Create and activate a virtual environment:**
   - Create a virtual environment by running:
     ```bash
     python -m venv .venv
     ```
   - **Activate the virtual environment**:
     - For **PowerShell** (VS Code default):
       ```bash
       .venv\Scripts\Activate.ps1
       ```

3. **Install the required dependencies**:
   Once the virtual environment is activated, install the necessary packages:
   ```bash
   pip install -r requirements.txt
   ```

## Dataset Description
The dataset is synthetically generated to represent common optical filter types using physically inspired spectral models.

### Dataset 
- One-dimensional absorption spectrum
- Wavelength range: 400–800 nm
- Number of points per spectrum: 3000
- Values normalized to [0, 1]

Due to the limited availability of optical spectral datasets, all spectra were synthetically generated. Spectra were generated by randomly varying physical parameters (e.g., absorption magnitude, cutoff slope, center wavelength) to introduce class diversity and improve model generalization. The Beer–Lambert law is expressed in terms of absorbance, which provides a linear relationship between spectral features and physical parameters. Gaussian noise, baseline offsets, and clipping to non-negative values were applied to further enhance realism and robustness.

The project includes both raw and preprocessed datasets:

- **Raw dataset** (`data/dataset/synthetic_spectra_dataset.npz`): Contains the simulated spectra (`X`), labels (`y`), and wavelength grid. This dataset is **not normalized or split** and may include duplicate samples.  
- **Preprocessed dataset** (`data/processed/spectra_preprocessed.npz`): Contains **normalized spectra**, categorical labels, and predefined training, validation, and test splits. This dataset is ready for direct use in model training and evaluation.  
- **Spectra preview** (`data/metadata/spectra_preview.txt`): Provides a sample preview of the spectra.  
- **Class mapping** (`data/metadata/class_mapping.json`): Maps numeric labels to filter types.
- **Recommendation:** Use `data/processed/spectra_preprocessed.npz` directly for training and evaluation unless you want to experiment with your own preprocessing. You can regenerate it if needed:
```bash
    python -m src.generate_spectra
```

### Classes

| Label |       Filter Type      |
|-------|------------------------|
|   0   |    Long-pass filter    |
|   1   |    Short-pass filter   |
|   2   |    Band-pass filter    |
|   3   | Neutral-density filter |


## Model architecture 
**Transformer (SpectralTransformer)**
- Input: normalized 1D spectra (batch_size, 401)
- Embedding: projects scalar input to d_model dimensions (default d_model=64)
- Positional Encoding: learnable positional embeddings added to each spectral point
- Encoder: 4-layer Transformer encoder (nhead=4, feedforward dimension=128)
- Pooling: global average pooling over the wavelength dimension
- Output: fully connected layer with softmax for classification into 4 filter types

**Convolutional Neural Network (SpectralCNN)**
- Input: normalized 1D spectra (batch_size, 401)
- Feature extraction:
    - Conv1: 1 -> 16 channels, kernel size 7
    - Conv2: 16 -> 32 channels, kernel size 5
    - Conv3: 32 -> 64 channels, kernel size 3
    - Max pooling applied after each conv layer
- Flattening: automatic calculation of flattened feature vector
- Classification head: 128-unit fully connected layer -> ReLU -> dropout -> 4-class output

**Notes:** 
- Both models use normalized input values [0,1] and categorical labels.
- The Transformer captures long-range spectral dependencies, while the CNN captures local spectral features.
- Both models output logits for 4 filter classes: long-pass, short-pass, band-pass, and notch.


## Usage 
### Training models
**CNN** 
```bash
python -m src.train_cnn --data_path data/processed/spectra_preprocessed.npz
```
The trained CNN model is saved to `models/baseline_cnn_best.path`

**Transformer**
```bash 
python -m src.train_transformer --data_path data/processed/spectra_preprocessed.npz
```
The trained transformer model is saved to `models/transformer_best.pth`

### Visualizing predictions 
**CNN**
```bash
python -m src.visualize_predictions --model_path models/baseline_cnn_best.path
```
**Transformer**
```bash
python -m src.visualize_predictions --model_path models/transformer_best.pth
```
**The outcomes of visualizing predictions**
1. **Visualization of the preprocessed training spectra** provides qualitative insight into the structure and separability of the dataset.
2. Example spectra plotted for each filter type show distinct and physically meaningful spectral shapes. Long-pass and short-pass filters exhibit sharp cutoff behavior at their respective wavelength regions, while band-pass filters display characteristic transmission windows bounded by two transitions. Neutral-density filters show relatively flat, wavelength-independent attenuation across the spectrum.
3. **Mean spectra** computed for each class further highlight these differences. Cutoff-based filters (long-pass and short-pass) are clearly distinguishable by their monotonic spectral transitions, while band-pass filters exhibit localized passbands. Neutral-density filters form a distinct class with nearly uniform absorption, making them easily separable from wavelength-dependent filters.
4. **Intra-class variability analysis** reveals that neutral-density filters have the lowest variance across wavelengths, indicating highly consistent spectral behavior. Band-pass filters show higher variability near transition regions, reflecting differences in bandwidth and cutoff sharpness. Long-pass and short-pass filters exhibit moderate variability around their cutoff wavelengths.

Overall, these visualizations confirm that the dataset is well-structured and physically interpretable, with clear inter-class differences and limited intra-class variation. This supports the strong classification performance observed for both CNN and Transformer models.

### Evaluating models
**CNN**
```bash 
python -m src.test_evaluation --model_path models/baseline_cnn_best.path --data_path data/processed/spectra_preprocessed.npz
```
**Transformer**
```bash 
python -m src.test_evaluation --model_path models/transformer_best.pth --data_path data/processed/spectra_preprocessed.npz
```
**The evaluation generates:**
- test accuracy and classification report for each model
- confusion matrices (normalized)
- multiclass ROC curves and AUC
- PCA on the combined dataset (train + test) and plots 2D visualization
- confidence histograms for predictions
- training curves from saved `data/logs/` (train/validation loss and accuracy)

## Results
### Overall Performance
| Model      | Accuracy | Precision | Recall | F1-score |
|------------|----------|-----------|--------|----------|
| CNN        | 99.44%   | 0.99      | 0.99   | 0.99     |
| Transformer| 97.98%   | 0.98      | 0.98   | 0.98     |

Both CNN and Transformer models achieve strong classification performance on the test set.  
The CNN slightly outperforms the Transformer in overall accuracy (99.44% vs. 97.98%) and shows consistently high precision, recall, and F1-scores across all filter classes. In particular, neutral-density filters are classified perfectly, while only minor confusion occurs among long-pass, short-pass, and band-pass filters due to overlapping spectral transitions.
The Transformer also performs robustly, though recall is slightly lower for band-pass filters, reflecting sensitivity to subtle inter-class similarities. Macro-averaged metrics remain high for both models, indicating balanced performance across classes.

### Confusion Matrix
Confusion matrix analysis reveals near-perfect class separation for the CNN, with minor confusion between long-pass and band-pass filters. The Transformer exhibits slightly higher misclassification rates for band-pass filters, consistent with its lower recall for this class. Both models achieve high true positive rates for neutral-density filters, which are easily distinguishable due to their uniform attenuation profiles.

### ROC / AUC
ROC–AUC analysis confirms strong class separability for both models, with near-perfect AUC values across all classes. The CNN demonstrates slightly more stable discrimination, while the Transformer remains highly competitive.

### PCA Visualization
PCA visualization of the combined training and test spectra shows clear clustering of filter types, with partial overlap between band-pass and cutoff-based filters near class boundaries. This explains the small number of observed misclassifications.

### Confidence and Training Curves
Prediction confidence histograms indicate that CNN predictions are highly confident, with probabilities concentrated near 1.0, while Transformer predictions show a slightly broader distribution, reflecting greater uncertainty near class boundaries.

Overall, the results highlight the effectiveness of CNNs for capturing localized spectral features, while Transformers provide strong performance by modeling global spectral context. Full quantitative metrics and additional visualizations are provided in the supplementary material.

## References
## References

1. Chroma Technology Corp., “Filter Characteristics,” *About Fluorescence*.  
Available: https://www.chroma.com/support/knowledge-center/about-fluorescence/filter-characteristics  
Accessed: Jan. 2026.

2. Edmund Optics, “Optical Filters,” *Knowledge Center*.  
Available: https://www.edmundoptics.com/knowledge-center/application-notes/optics/optical-filters/  
Accessed: Jan. 2025.

3. R. Hang, Q. Liu, D. Hong, P. Ghamisi, and S. Bhattacharyya,  
“Hyperspectral image classification with attention-aided CNNs,”  
*IEEE Transactions on Geoscience and Remote Sensing*, vol. 59, no. 3, pp. 2281–2293, 2020.

4. E. Hecht, *Optics*, 5th ed. Boston, MA, USA: Pearson, 2017.

5. D. Hong et al.,  
“SpectralFormer: Rethinking hyperspectral image classification with transformers,”  
*IEEE Transactions on Geoscience and Remote Sensing*, vol. 60, pp. 1–15, 2021.

6. W. Hu, Y. Huang, L. Wei, F. Zhang, and H. Li,  
“Deep convolutional neural networks for hyperspectral image classification,”  
*Journal of Sensors*, vol. 2015, Article ID 258619, pp. 1–12, 2015.
"# Comparison-of-CNN-and-Transformer-Models-for-Optical-Filter-Classification" 
